---
title: "TOON: Paga menos a OpenAI y dile adioÃÅs al JSON"
date: "12 de Enero de 2026"
edition: 10
source: "https://www.blog.lvrpiz.com/p/toon-vs-json-ahorrar-tokens-llm"
---

# TOON: Paga menos a OpenAI y dile adioÃÅs al JSON

Te explico queÃÅ es TOON (Token-Oriented Object Notation) y coÃÅmo empezar a usarlo en tus proyectos para ahorrar tokens con LLMs como ChatGPT o Gemini

## Contenido

- [¬øQu√© es Token-Oriented Object Notation (TOON)?](#qu-es-token-oriented-object-notatio)
- [C√≥mo convertir JSON a TOON (y viceversa)](#cmo-convertir-json-a-toon-y-vicever)

  - [C√≥mo instalar y usar la librer√≠a TOON en Node.js (npm/pnpm)](#cmo-instalar-y-usar-la-librera-toon)
- [Limitaciones de TOON: ¬øVolvemos a YAML o JSON?](#limitaciones-de-toon-volvemos-a-yam)
- [An√°lisis de benchmarks: ¬øEntienden los LLMs el for ‚Ä¶](#anlisis-de-benchmarks-entienden-los)

No s√© si has o√≠do hablar de TOON. Si no te suena, tranquilo, est√°s en el sitio indicado. Y si ya lo conoces, qu√©date, porque traigo benchmarks que te van a gustar y adem√°s te regalo una herramienta gratuita que he desarrollado para transformar JSON a TOON. Vamos all√°.

La premisa de TOON es simple: es un **formato de serializaci√≥n** como JSON, pero dise√±ado **para ahorrar tokens al pas√°rselo a un LLM**.

Por darte un ejemplo. Seg√∫n los creadores de TOON, si tienes 1 mill√≥n de peticiones al mes, pasar de JSON a **TOON podr√≠a ahorrarte unos 55 millones de tokens**. Si usas un modelo premium como Claude 3 Opus (que cuesta aprox. 15 $/1M tokens), eso son m√°s de **825 $ al mes que te dejas de gastar**. (Aqu√≠ los devs haciendo un poco de cherry picking pero bueno‚Ä¶ entendemos el concepto).

La idea es brutal. Peeero, como siempre, no es oro todo lo que reluce. El ahorro de tokens es solo una parte de la ecuaci√≥n, la otra es si el modelo entiende bien ese formato.

Hoy te cuento qu√© es TOON, c√≥mo usarlo e integrarlo en tu flujo de trabajo y por qu√© todav√≠a hay que mirarlo con cierta cautela.

## TOON vs JSON: La batalla por el ahorro de tokens en LLMs

Cualquiera que haya trabajado con las APIs de OpenAI, Gemini, Claude‚Ä¶ sabe que el JSON, aunque es un est√°ndar, es muy verboso.

Cada vez que env√≠as un array de objetos, **repites las mismas claves** ("id", "name", "role") una y otra vez. Todos esos corchetes ([]), llaves ({}), comas y comillas dobles **suman tokens**. Y **cada token cuesta dinero**.

Mira este ejemplo de JSON:

```
{"users":[{"id":1,"name":"Alice","role":"admin"},{"id":2,"name":"Bob","role":"user"}]}
```

YAML mejora un poco al quitar llaves y comillas, pero TOON va un paso m√°s all√°, inspir√°ndose en la estructura de CSV para los arrays. Equivalencia en TOON:

```
users[2]{id,name,role}:
  1,Alice,admin
  2,Bob,user
```

Para que veas la diferencia real de tokens (calculada con [tiktokenizer](https://tiktokenizer.vercel.app)), mira esta comparativa. Ya puedes ver por d√≥nde van los tiros: **las claves se declaran una sola vez en la cabecera del array, y los datos van en filas limpias**.

Comparativa de Tokens JSON vs TOON con el tokenizador de GPT-4

## TOON explicado: ¬øQu√© es Token-Oriented Object Notation (TOON)?

TOON (Token-Oriented Object Notation) es un **formato de serializaci√≥n compacto y legible por humanos**, dise√±ado espec√≠ficamente para pasar datos estructurados a LLMs **usando muchos menos tokens**.

Es importante entender que **no busca reemplazar a JSON** en tus APIs o bases de datos. Su objetivo es ser una capa de traducci√≥n: usas JSON en tu l√≥gica de backend, **lo conviertes a TOON justo antes de enviarlo al LLM**, y te ahorras unos tokens por el camino.

Token-Oriented Object Notation (TOON)

Uno de sus puntos fuertes son los arrays de objetos uniformes: muchas filas con la misma estructura. **Para datos muy anidados o no uniformes, el propio JSON compacto puede ser m√°s eficiente**.

El formato tiene una especificaci√≥n completa (v2.0) y se basa en dos ideas:

- Estructura por **indentaci√≥n** (como YAML) para objetos anidados.
- Formato **tabular** (como CSV) para los arrays de objetos, declarando las claves {id,name,role} una vez.

Adem√°s, incluye *guardrails* para el LLM, como `users[2]`, que le dice expl√≠citamente al modelo cu√°ntos elementos esperar, ayudando a validar que los datos no est√©n truncados.

```
[2]:
  - name: Alice Smith
    id: 101
    skills[3]: JavaScript,CSS,HTML
  - name: Bob Johnson
    id: 102
    skills[3]: Python,SQL,Java
```

## Primeros pasos con TOON: C√≥mo convertir JSON a TOON (y viceversa)

Lo mejor de TOON es que **NO tienes que explicarle el formato al LLM**. Los modelos lo pillan r√°pido al parecerse a YAML y CSV.

Para empezar simplemente dale tus datos en TOON al LLM. Aqu√≠ tienes un **ejemplo** m√≠nimo en formato TOON para que pruebes:

```
users[3]{id,name,role}:

  1,Alice,admin

  2,Bob,user

  3,Charlie,user
```

Si le pides a ChatGPT que analice los usuarios con el rol *user* obtenemos lo siguiente:

Como ves, los LLMs no tienen gran problema entendiendo TOON sencillos (luego analizaremos benchmarks con ejemplos complejos). Ahora te preguntar√°s: √Ålvaro, ¬øc√≥mo paso mi JSON a TOON?

Para facilitar las pruebas y ver el ahorro real, he desarrollado una **peque√±a herramienta online gratuita**: <https://jsontotoon.lvrpiz.com>

Conversor de JSON a TOON bidireccional

Es un **conversor bidireccional**: pegas tu JSON y te da el TOON, y viceversa. Pero lo m√°s √∫til es que he implementado un **an√°lisis de tokens** usando el tokenizador cl100k\_base (el de GPT-4), algo que no he visto en otros conversores y que nos da una **idea del ahorro que vamos a tener.**

Te dice exactamente cu√°ntos tokens te ahorras frente a JSON formateado y compacto, y qu√© porcentaje de tus datos es elegible para el formato tabular.

An√°lisis de eficiencia de Tokens TOON vs JSON

Ahora bien, esta herramienta est√° muy bien para jugar, probar combinaciones, ver el **impacto en Tokens** de cambiar a TOON y tener una estimaci√≥n del ahorro pero ChatGPT no nos cobra m√°s si interactuamos con su aplicaci√≥n, nos cobra por Tokens en su API. ¬øC√≥mo integramos el formato TOON en nuestras llamadas a la API? üëâüèª `@toon-format/toon`

### C√≥mo instalar y usar la librer√≠a TOON en Node.js (npm/pnpm): `@toon-format/toon`

Si quieres integrarlo en tu backend (Node.js), la instalaci√≥n es est√°ndar:

```
# npm
npm install @toon-format/toon

# pnpm
pnpm add @toon-format/toon
```

Y el uso b√°sico es muy directo. Usas la **funci√≥n encode** para convertir tu objeto JSON a un string TOON:

```
import { encode } from '@toon-format/toon'

const data = {
  users: [
    { id: 1, name: 'Alice', role: 'admin' },
    { id: 2, name: 'Bob', role: 'user' }
  ]
}

const toonString = encode(data)
console.log(toonString)

// users[2]{id,name,role}:
//   1,Alice,admin
//   2,Bob,user
```

Con esto ya puedes pasar tus JSON a formato TOON antes de volcarlos al LLM para ahorrarte unos tokens en cada llamada. Tambi√©n tienes la **funci√≥n decode**(toonString) para hacer el camino inverso.

## Limitaciones de TOON: ¬øVolvemos a YAML o JSON?

Aqu√≠ es donde toca analizar nuestros datos y decidir. **TOON es excelente con arrays de objetos que sean uniformes**. Si tus datos no encajan ah√≠, el ahorro desaparece e incluso puede ser contraproducente.

No deber√≠as usar TOON si:

- Tus **datos son muy anidados o no uniformes**: Si tienes un JSON de configuraci√≥n complejo, con muchos niveles y objetos que no comparten claves, el JSON compacto ([minificado](https://github.com/getify/JSON.minify)) probablemente usar√° menos tokens.
- Tienes **arrays semi-uniformes**: Si en un array algunos objetos tienen 3 claves y otros 5, TOON no puede usar el modo tabular y pasa a un modo "lista" (con guiones, como YAML) que es menos eficiente.
- Son **datos puramente tabulares y planos**: Si solo tienes una tabla simple, un CSV de toda la vida sigue siendo mejor en cuanto a tokens. Aqu√≠ TOON a√±ade un peque√±o overhead (un 5-10% m√°s que CSV) a cambio de dar m√°s estructura (el [N] y las claves {}), lo cual ayuda al LLM a no equivocarse.

Si usas la [herramienta](https://jsontotoon.lvrpiz.com) que te comentaba previamente y el formato de tus datos no es √≥ptimo para TOON te saldr√° un warning y lo ver√°s reflejado a mayores en el an√°lisis de Tokens.

Aviso de JSON no uniforme detectado en la herramienta de JSONtoTOON

## An√°lisis de benchmarks: ¬øEntienden los LLMs el formato TOON?

De nada sirve ahorrar un 40% en tokens si el LLM se confunde y te da una respuesta incorrecta. Aqu√≠ es donde las cosas se ponen interesantes. Vamos a analizar los benchmarks disponibles:

Los benchmarks oficiales de TOON ([enlace](TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   26.9  ‚îÇ  73.9% acc  ‚îÇ  2,744 tokens JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë   22.9  ‚îÇ  70.7% acc  ‚îÇ  3,081 tokens YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   18.6  ‚îÇ  69.0% acc  ‚îÇ  3,719 tokens JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   15.3  ‚îÇ  69.7% acc  ‚îÇ  4,545 tokens XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   13.0  ‚îÇ  67.1% acc  ‚îÇ  5,167 tokens) a su GitHub) son muy positivos. En sus pruebas de recuperaci√≥n de datos (con modelos como GPT-5-nano y Gemini-2.5-flash), TOON consigue una precisi√≥n media del 73.9%, **superando al JSON (69.7%) y usando un 39.6% menos de tokens**.

```
TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   26.9  ‚îÇ  73.9% acc  ‚îÇ  2,744 tokens
JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë   22.9  ‚îÇ  70.7% acc  ‚îÇ  3,081 tokens
YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   18.6  ‚îÇ  69.0% acc  ‚îÇ  3,719 tokens
JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   15.3  ‚îÇ  69.7% acc  ‚îÇ  4,545 tokens
XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   13.0  ‚îÇ  67.1% acc  ‚îÇ  5,167 tokens
```

Peeero, he encontrado un [an√°lisis de un tercero](https://www.improvingagents.com/blog/toon-benchmarks) que pone esto en duda y obliga a mirar los datos con m√°s calma.

En sus pruebas, la cosa cambia, y es crucial analizar el **trade-off entre precisi√≥n y tokens**.

### Test con Datos Tabulares

A primera vista, si solo miras la columna de precisi√≥n, **TOON (47.5%) parece rendir peor que formatos que consumen m√°s tokens como JSON (52.3%) o YAML (54.7%)**.

| Formato | Accuracy | **Intervalo de confianza del 95 %** | Tokens |
| --- | --- | --- | --- |
| Markdown-KV | **60.7%** | 57.6% ‚Äì 63.7% | 52,104 |
| XML | 56.0% | 52.9% ‚Äì 59.0% | **76,114** |
| YAML | 54.7% | 51.6% ‚Äì 57.8% | 55,395 |
| HTML | 53.6% | 50.5% ‚Äì 56.7% | 75,204 |
| JSON | 52.3% | 49.2% ‚Äì 55.4% | 66,396 |
| **TOON** | **47.5%** | **44.4% ‚Äì 50.6%** | **21,518** |
| JSONL | 45.0% | 41.9% ‚Äì 48.1% | 54,407 |
| CSV | **44.3%** | 41.2% ‚Äì 47.4% | **19,524** |

Pero, ahora mira la columna de Tokens.

- JSON: 52.3% de precisi√≥n costando 66,396 tokens.
- TOON: 47.5% de precisi√≥n costando 21,518 tokens.

Aqu√≠ se ve el **trade-off real**: **TOON usa un 68% menos de tokens que JSON**. La pregunta que debes hacerte es: **¬øestoy dispuesto a asumir una ca√≠da de ~5 puntos en la precisi√≥n a cambio de pagar casi 3 veces menos?**

Para datos tabulares, **TOON compite en eficiencia con CSV** (que saca una precisi√≥n y un coste similar), pero queda claro que los formatos m√°s verbosos como JSON o YAML obtienen algo m√°s de precisi√≥n, **pagando un precio mucho m√°s alto**.

### Test con Datos Anidados

Aqu√≠ es donde TOON sale peor parado y se confirma lo que te comentaba en la secci√≥n anterior.

| Formato | Accuracy | **Intervalo de confianza del 95 %** | Tokens |
| --- | --- | --- | --- |
| YAML | **62.1%** | 59.1%, 65.1% | 42,477 |
| Markdown | 54.3% | 51.2%, 57.4% | **38,357** |
| JSON | 50.3% | 47.2%, 53.4% | 657,933 |
| XML | 44.4% | 41.3%, 47.5% | 68,804 |
| **TOON** | **43.1%** | **40.0%, 46.2%** | **45,436** |

En este escenario de datos anidados, **TOON no solo fue el formato con la peor precisi√≥n (43.1%), sino que adem√°s us√≥ m√°s tokens que YAML (45k vs 42k)**, que encima le sac√≥ 19 puntos de precisi√≥n.

El **punto fuerte de TOON son los datos tabulares uniformes**, pero para estructuras anidadas, YAML parece una opci√≥n mucho m√°s equilibrada.

#### Por resumir‚Ä¶ ¬øQu√© significa todo esto?

Todav√≠a es **pronto para sacar conclusiones**. Los benchmarks son contradictorios y dependen mucho del modelo y del tipo de datos que usemos.

Es muy probable que formatos como JSON o YAML funcionen mejor (aunque cuesten m√°s) simplemente **porque los LLMs han sido entrenados con trillones de ejemplos de ellos**.

**TOON es nuevo y no est√° en los datos de entrenamiento. Es posible que su rendimiento mejore a medida que los modelos se reentrenen y "aprendan" el formato.**

**Mi recomendaci√≥n**: si trabajas con arrays de objetos muy grandes y uniformes, donde el coste de los tokens es un problema real, dale una oportunidad. Pasa tus datos por la herramienta de conversi√≥n, mira el ahorro potencial y haz pruebas A/B de precisi√≥n con tus propios prompts.

Para datos anidados o cr√≠ticos donde la precisi√≥n es lo √∫nico que importa, de momento me quedar√≠a con JSON compacto o YAML.

Hasta el pr√≥ximo mi√©rcoles,

√Ålvaro